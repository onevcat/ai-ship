---
title: "AI 让提早优化更有价值"
date: "2026-01-25"
tools: ["codex"]
category: "工作"
action_button:
  text: "阅读 Chroma 原文"
  url: "https://onevcat.com/2026/01/chroma/"
---

在写 Chroma（一个 Swift 终端语法高亮库）和 `ca`（`cat` 的高亮替代品）时，最值得记录的并不是功能本身，而是性能优化被 AI 放大后的价值：在持续 benchmark 驱动的迭代下，tokenizer 与 renderer 的性能被推到原来的十倍左右，优化过程可以一路做到“满意为止”。

这次实践的核心方式很朴素：把 benchmark 当作一等公民，让 AI 读代码、找热点、给出多个方案，再用理论估算收益；每次只做小改动，立即跑基准测量，用结果反馈下一轮改进。优化不再是几次试错后就疲惫的体力活，而是“提出假设—验证—修正”的科学实验。AI 的价值不是某个天才微优化，而是把试错成本压到足够低，让我们愿意把优化做完。

两个典型优化也说明了这一点：把 tokenizer/renderer 从 batch 流水线改成 streaming，系统性降低内存和拷贝成本；为 ASCII 主导的实际输入分布加 fast-path，再在非 ASCII 时回退到安全路径。它们都不算“灵感一击”，却需要大量细致改动与验证，而这恰恰是 AI 擅长扛住的部分。

因此，“过早优化是万恶之源”的经验在 AI 时代需要重新理解。过去我们避免过早优化，是因为试错昂贵、脑力与时间难以投入；但在 AI 开发中，这些成本被显著降低，许多优化可以提前布局、尽早验证并反复迭代。我也越来越相信：提早优化并不违背工程理性，反而是一条正确而高效的道路。
